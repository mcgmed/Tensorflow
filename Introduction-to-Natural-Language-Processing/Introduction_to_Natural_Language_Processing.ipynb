{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMssyd1ELCHEdyal8Uo9KKV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcgmed/Tensorflow/blob/main/Introduction-to-Natural-Language-Processing/Introduction_to_Natural_Language_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMH_snDSS_o-",
        "outputId": "db3c4abb-2373-4000-d85c-63dfb901d113"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'today': 1, 'is': 2, 'a': 3, 'day': 4, 'sunny': 5, 'rainy': 6}\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "sentences = ['Today is a sunny day', 'Today is a rainy day']\n",
        "tokenizer = Tokenizer(num_words=100)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['Today is a sunny day', 'Today is a rainy day', 'Is it sunny today?'] # Be careful about 'today' word with question mark at the last sentence.\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index) # Tokenizer can understand that two words are just same.\n",
        "# This behavior is controlled by the filters parameter to the tokenizer, which defaults to removing all punctuation except the apostrophe character."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMvhxPnwXHdg",
        "outputId": "44c71bbb-18be-4d7a-cdc8-461c60d8af1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'today': 1, 'is': 2, 'a': 3, 'day': 4, 'sunny': 5, 'rainy': 6, 'it': 7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDXyvr40kpRF",
        "outputId": "90a97bb2-229c-4bd4-e250-2ecc6decf528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 2, 3, 5, 4], [1, 2, 3, 6, 4], [2, 7, 5, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = ['Today is a snowy day', 'Will it be rainy tomorrow?']\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data)\n",
        "print(word_index)\n",
        "print(test_sequences)\n",
        "# It converted test_data according to sentences list. It hasn't converted new words."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sazEAwP6lthA",
        "outputId": "cb445891-a145-4d9b-dd37-40c5a3357cb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'today': 1, 'is': 2, 'a': 3, 'day': 4, 'sunny': 5, 'rainy': 6, 'it': 7}\n",
            "[[1, 2, 3, 4], [7, 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Using out-of-vocabulary tokens**"
      ],
      "metadata": {
        "id": "s9LFbTblnJtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words = 100, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data)\n",
        "print(word_index)\n",
        "print(test_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0-4ylMJm0wG",
        "outputId": "28f0ec88-7952-4ad9-8086-2beea60d84a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<OOV>': 1, 'today': 2, 'is': 3, 'a': 4, 'sunny': 5, 'day': 6, 'rainy': 7, 'it': 8}\n",
            "[[2, 3, 4, 1, 6], [1, 8, 1, 7, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Understanding padding**"
      ],
      "metadata": {
        "id": "o75CoTx4Iwad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "'Today is a sunny day',\n",
        "'Today is a rainy day',\n",
        "'Is it sunny today?',\n",
        "'I really enjoyed walking in the snow today'\n",
        "]\n",
        "\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uz6ij5sFIwDh",
        "outputId": "b2d9e399-ff75-43cd-a6fe-0737cacbc69f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 3, 4, 5, 6],\n",
              " [2, 3, 4, 7, 6],\n",
              " [3, 8, 5, 2],\n",
              " [9, 10, 11, 12, 13, 14, 15, 2]]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "padded = pad_sequences(sequences)\n",
        "print(padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZFbJVovLf71",
        "outputId": "6d66157a-f981-4532-939b-2b7cef09631f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  2  3  4  5  6]\n",
            " [ 0  0  0  2  3  4  7  6]\n",
            " [ 0  0  0  0  3  8  5  2]\n",
            " [ 9 10 11 12 13 14 15  2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want your sequences to be padded with zeros at the end, you can use:"
      ],
      "metadata": {
        "id": "JwgJO3Z5PGQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "padded = pad_sequences(sequences, padding='post')\n",
        "print(padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45B968K7PHlg",
        "outputId": "d7320b2b-4f73-4785-ed88-685012ab3e63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2  3  4  5  6  0  0  0]\n",
            " [ 2  3  4  7  6  0  0  0]\n",
            " [ 3  8  5  2  0  0  0  0]\n",
            " [ 9 10 11 12 13 14 15  2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What if you don’t want this, perhaps because you have one crazy long sentence that means you’d have too much padding in the padded sequences? To fix that you can use the **maxlen** parameter, specifying the desired maximum length, when calling **pad_sequences**, like this:"
      ],
      "metadata": {
        "id": "0qMyuk_hPbAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "padded = pad_sequences(sequences, padding='post', maxlen=6)\n",
        "print(padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86-BhwVbPlBm",
        "outputId": "a29db14b-e13f-47e9-fadb-c3724fa4f718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2  3  4  5  6  0]\n",
            " [ 2  3  4  7  6  0]\n",
            " [ 3  8  5  2  0  0]\n",
            " [11 12 13 14 15  2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now your padded sequences are all the same length, and there isn’t too much padding. You have lost some words from your longest sentence, though, and they’ve been truncated from the beginning. What if you don’t want to lose the words from the beginning and instead want them truncated from the end of the sentence? You can override the default behavior with the **truncating** parameter, as follows:"
      ],
      "metadata": {
        "id": "WRR42dSiQCem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "padded = pad_sequences(sequences, padding='post', maxlen=6, truncating='post')\n",
        "print(padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ip7O6LbiQBIY",
        "outputId": "d19dfbe0-ae4f-43b8-934a-fd4dee3beac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2  3  4  5  6  0]\n",
            " [ 2  3  4  7  6  0]\n",
            " [ 3  8  5  2  0  0]\n",
            " [ 9 10 11 12 13 14]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Removing Stopwords and Cleaning Text**"
      ],
      "metadata": {
        "id": "yiWandiLVpQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first is to strip out HTML tags. Fortunately, there’s a library called BeautifulSoup that makes this straightforward. For example, if your sentences contain HTML tags such as >br>, they’ll be removed by this code:"
      ],
      "metadata": {
        "id": "6sdErlB1WOWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "soup = BeautifulSoup(sentence)\n",
        "sentence = soup.get_text()"
      ],
      "metadata": {
        "id": "8dzT4XadVtPm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}